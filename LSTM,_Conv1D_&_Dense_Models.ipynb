{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfehjCy896Fd"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-YOqYMDEYL6"
      },
      "outputs": [],
      "source": [
        "# Fix randomness and hide warnings\n",
        "seed = 42\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_2xZB7bEbAW"
      },
      "outputs": [],
      "source": [
        "# Import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7vlAwP2EcKT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16)\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRK9IPIc-ZEz"
      },
      "source": [
        "### Load and process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11x-DOZB3I29"
      },
      "outputs": [],
      "source": [
        "if UNZIP_DATASET:\n",
        "    !unzip 'training_dataset.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3kx8HT2oZlK"
      },
      "outputs": [],
      "source": [
        "# here we import the dataset we need depending on the model. In this case train6 was created in order to contain sequences of length 206. We used train6 for the best model.\n",
        "\n",
        "train_data = pd.DataFrame(np.load(\"train6.npy\"))\n",
        "categories = pd.DataFrame(np.load(\"cat6.npy\",allow_pickle=True),columns=['Category']) #contains category of the series: {'A', 'B', 'C', 'D', 'E', 'F'}."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG8wWcjESXwN"
      },
      "outputs": [],
      "source": [
        "window=200\n",
        "telescope=6 # it depends by the dataset that we import\n",
        "\n",
        "train_indices = list(range(7000)) + list(range(7061, len(train_data)))\n",
        "\n",
        "X_train = train_data.iloc[train_indices, :-telescope]\n",
        "Y_train = train_data.iloc[train_indices, -telescope:]\n",
        "X_test = train_data.iloc[7001:7061, :-telescope]\n",
        "Y_test = train_data.iloc[7001:7061, -telescope:]\n",
        "\n",
        "# Reset of the indexes\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "Y_train = Y_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "Y_test = Y_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWUHKg87VEG8"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train.shape[1]\n",
        "output_shape = Y_train.shape[1]\n",
        "input_shape, output_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lSJPdWeFtaM"
      },
      "source": [
        "### Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZZfiwMUFtaN"
      },
      "outputs": [],
      "source": [
        "def build_CONV_LSTM_model(input_shape, output_shape):\n",
        "\n",
        "    # Define the input layer\n",
        "    input_layer = tfkl.Input(shape=(input_shape), name='input_layer')\n",
        "    # Reshape the input in order to use bidirectional LSTM\n",
        "    reshaped_layer = tfkl.Reshape((1, input_shape), name='reshape_layer')(input_layer)\n",
        "\n",
        "    x = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True, name='lstm'), name='bidirectional_lstm')(reshaped_layer)\n",
        "    x = tfkl.Bidirectional(tfkl.LSTM(64))(x)\n",
        "\n",
        "    x = tfkl.Dense(128, activation='relu', name='dense1')(x)\n",
        "    x = tfkl.Dense(64, activation='relu', name='dense2')(x)\n",
        "\n",
        "    output_layer = tfkl.Dense(output_shape, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='CONV_LSTM_model')\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H8JRF6QFtaO"
      },
      "outputs": [],
      "source": [
        "model = build_CONV_LSTM_model(input_shape, output_shape)\n",
        "model.summary()\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF0rSxAdFtaP"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 200\n",
        "\n",
        "history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_split=.1,\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=6, factor=0.1, min_lr=1e-5)\n",
        "    ]\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZh-os_OFtaP"
      },
      "outputs": [],
      "source": [
        "best_epoch = np.argmin(history['val_loss'])\n",
        "plt.figure(figsize=(17,4))\n",
        "plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.title('Mean Squared Error')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(18,3))\n",
        "plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SafxAwmjFtaQ"
      },
      "outputs": [],
      "source": [
        "model.save('DirectForecasting0_variation_phase2_206')\n",
        "#del model\n",
        "#model = tfk.models.load_model('DirectForecasting3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTwYuHHDVRyG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(Y_test, model.predict(X_test))\n",
        "print(f'Mean Squared Error: {mse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWDcCRHMGv24"
      },
      "source": [
        "### Model with CONV1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlAKhbxqGv3E"
      },
      "outputs": [],
      "source": [
        "def build_CONV_LSTM_model(input_shape, output_shape):\n",
        "\n",
        "    input_layer = tfkl.Input(shape=(input_shape), name='input_layer')\n",
        "    reshaped_layer = tfkl.Reshape((1, input_shape), name='reshape_layer')(input_layer)\n",
        "\n",
        "    x = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True, name='lstm'), name='bidirectional_lstm')(reshaped_layer)\n",
        "    x = tfkl.Conv1D(128, 3, padding='same', activation='relu', name='conv1')(x)\n",
        "    x = tfkl.Conv1D(64, 3, padding='same', activation='relu', name='conv2')(x)\n",
        "    x = tfkl.Bidirectional(tfkl.LSTM(32))(x)\n",
        "    x = tfkl.Dense(32, activation='relu', name='dense1')(x)\n",
        "    output_layer = tfkl.Dense(output_shape, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='CONV_LSTM_model')\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJkDv9TGGv3E"
      },
      "outputs": [],
      "source": [
        "model = build_CONV_LSTM_model(input_shape, output_shape)\n",
        "model.summary()\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqTFmiCaGv3E"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 200\n",
        "\n",
        "history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_split=.1,\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=6, factor=0.1, min_lr=1e-5)\n",
        "    ]\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JBtnSfIGv3E"
      },
      "outputs": [],
      "source": [
        "best_epoch = np.argmin(history['val_loss'])\n",
        "plt.figure(figsize=(17,4))\n",
        "plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.title('Mean Squared Error')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(18,3))\n",
        "plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RNX5OehGv3E"
      },
      "outputs": [],
      "source": [
        "model.save('DirectForecasting0')\n",
        "#del model\n",
        "#model = tfk.models.load_model('DirectForecasting3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yTD2UgwGv3F"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(Y_test, model.predict(X_test))\n",
        "print(f'Mean Squared Error: {mse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BkoY3tdHaZv"
      },
      "source": [
        "### Model with ATTENTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ywZt-K0H9sb"
      },
      "outputs": [],
      "source": [
        "class attention(tf.keras.layers.Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super(attention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1),\n",
        "                               initializer='random_normal', trainable=True)\n",
        "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1),\n",
        "                               initializer='zeros', trainable=True)\n",
        "        super(attention, self).build(input_shape)\n",
        "\n",
        "    def call(self,x):\n",
        "        # Alignment scores. Pass them through tanh function\n",
        "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x,self.W)+self.b)\n",
        "        # Remove dimension of size 1\n",
        "        e = tf.keras.backend.squeeze(e, axis=-1)\n",
        "        # Compute the weights\n",
        "        alpha = tf.keras.backend.softmax(e)\n",
        "        # Reshape to tensorFlow format\n",
        "        alpha = tf.keras.backend.expand_dims(alpha, axis=-1)\n",
        "        # Compute the context vector\n",
        "        context = x * alpha\n",
        "        context = tf.keras.backend.sum(context, axis=1)\n",
        "        return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_VEJLzjHaZ4"
      },
      "outputs": [],
      "source": [
        "def build_CONV_LSTM_model(input_shape, output_shape):\n",
        "\n",
        "    input_layer = tfkl.Input(shape=(input_shape), name='input_layer')\n",
        "    reshaped_layer = tfkl.Reshape((1, input_shape), name='reshape_layer')(input_layer)\n",
        "\n",
        "    x = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True, name='lstm'), name='bidirectional_lstm')(reshaped_layer)\n",
        "    x = tfkl.Conv1D(128, 3, padding='same', activation='relu', name='conv1')(x)\n",
        "    x = tfkl.Conv1D(64, 3, padding='same', activation='relu', name='conv2')(x)\n",
        "    x = tfkl.Conv1D(9, 3, padding='same', activation='relu', name='conv3')(x)\n",
        "    output_layer = attention()(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='CONV_LSTM_model')\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOTmBxYJHaZ5"
      },
      "outputs": [],
      "source": [
        "model = build_CONV_LSTM_model(input_shape, output_shape)\n",
        "model.summary()\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joyHQ2zhHaZ5"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 200\n",
        "\n",
        "history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_split=.1,\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=6, factor=0.1, min_lr=1e-5)\n",
        "    ]\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZo7SOFnHaZ5"
      },
      "outputs": [],
      "source": [
        "best_epoch = np.argmin(history['val_loss'])\n",
        "plt.figure(figsize=(17,4))\n",
        "plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.title('Mean Squared Error')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(18,3))\n",
        "plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_-D4EMfHaZ5"
      },
      "outputs": [],
      "source": [
        "model.save('DirectForecasting0_attention')\n",
        "#del model\n",
        "#model = tfk.models.load_model('DirectForecasting3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foggyFYDHaZ5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(Y_test, model.predict(X_test))\n",
        "print(f'Mean Squared Error: {mse}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
